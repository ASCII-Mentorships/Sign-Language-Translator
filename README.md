# Sign-Language-Translator

## Project Idea
End Goal is to develop an in-house device that can do the following:
**Gesture-Translation:** The images captured from the gestures of a person are processed in real-time and output the audio (display the text on the screen) corresponding to the gesture (or combination of gestures),
**Audio-Translation:** The audio from a person is taken as an input and an appropriate gesture (or combination of gestures) is output on the screen (we will have to create standard templates for the gestures) in real-time.


## Learning Outcomes
 what will students learn

## Plan of Action

The main the aspects of this project would be to deal right with the basic of identifying thr  relevant datasets and papers ans directly the final steps of deployment odf theis algorithms 




## TimeLine


## Pre-req
 Python 
 Git
 Basic concepts of Computer Vision
 Passion for  Learning

## End- Result


## Expectations

## Project Mentors
Viraj V Aute
Hardik Shah
