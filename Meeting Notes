02-09-22

1) There are 3 mentors for the project - Hardik Shah , Ricky Patel and Viraj Aute.

2) We will be dividing you all on basis of your interests and work into 2 groups
      a) Audio-Translation
      b) Gesture- Translation
      (Read about the problem statement in readme file )
      
3) The task for 1st week is to look around for research papers and datasets, and try to think of different ways in which we could solve the problem.
    For the 1st week we dont want you to write any code but explore stuff and come up with ideas, add you literature reviews or ideas in this github repo
    Also along with accuracy of the model , the size of the model is also a very important factor for us
    
4) We would like to have a weekly meeting with you all so we need to decide on the timings


10-09-22

1) Mentees are asked to review research papers related to the problem statement and add them to the GitHub repo. Preferably atleast three papers. Important part is to
   note how the researcher's implemented their model, the accuracy, the feasibility and the dataset used to train the model. 

2) To obtain research papers along with code of the model implemented, papers with code can be used. Link:- https://paperswithcode.com/
   It is not required to understand the entirety of the paper, but the abstract, figures(depicting methods of implementation) and the result section are important. 

3) The task for this week (till next saturday) is to go through research papers and obtain the code used by the researchers for sign language/gesture translation.
   Use the code on your own computers and to get some understanding of the accuracy of the model as well as the method used to implement it. See how it works.
   If some code/application does not work on your machine, Google Colab can be used to test the code. But videos cannot be uploaded to Colab.

4) A whatsapp group will be created where all the mentees will be added/requested to join.

